{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Stock Market Ontology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import pandas as pd\n",
    "import math\n",
    "import os\n",
    "import time\n",
    "import numpy\n",
    "import tinvest\n",
    "from tinvest import CandleResolution\n",
    "from rdflib import URIRef\n",
    "from rdflib import Graph, Literal\n",
    "from rdflib.namespace import RDF\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fundamental_metrics = ['Index', 'P/E', 'P/S', 'Dividend %', 'Payout', 'Beta']\n",
    "\n",
    "all_metrics = [*['Name', 'Sector', 'Country'], *fundamental_metrics]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get stocks tickers from [Nasdaq](https://www.nasdaq.com/market-activity/stocks/screener) and save to CSV\n",
    "Use saved tickets to get and parse data from resource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Read tickers from Nasdaq CSV file\n",
    "def get_stock_ticker_list(file_name, ticker_field_name):\n",
    "    tickers = []\n",
    "    with open(file_name, newline='') as file:\n",
    "        reader = csv.DictReader(file, [ticker_field_name])\n",
    "        for row in reader:\n",
    "            ticker = row[ticker_field_name]\n",
    "            tickers.append(ticker)\n",
    "    return tickers[1:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing data from [FINVIZ](https://finviz.com/quote.ashx)\n",
    "\n",
    "Received values:\n",
    "\n",
    "* Name\n",
    "* Sector\n",
    "* Country\n",
    "* P/E\n",
    "* P/S\n",
    "* Dividend %\n",
    "* Payout\n",
    "* Beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "resourceUrl = 'https://finviz.com/quote.ashx'\n",
    "\n",
    "\n",
    "def get_fundamental_metric(soup, metric=None):\n",
    "    if metric is None:\n",
    "        metric = fundamental_metrics\n",
    "    # Search in table with fundamental metrics\n",
    "    name_cell = soup.find(text=metric) # First search header cell\n",
    "    value_cell = name_cell.find_next(class_='snapshot-td2') # Next search closest cell\n",
    "    return value_cell.text\n",
    "\n",
    "\n",
    "def get_name_sector_country(soup):\n",
    "    table = soup.find(attrs={'data-testid': 'quote-data-content'})\n",
    "    links = table.findAll(class_='tab-link')\n",
    "\n",
    "    name = links[0].find('b').text\n",
    "    sector = links[1].text\n",
    "    country = links[3].text\n",
    "\n",
    "    return [('Name', name), ('Sector', sector), ('Country', country)]\n",
    "\n",
    "\n",
    "def get_fundamental_data(df):\n",
    "    notFound = []\n",
    "    for symbol in df.index:\n",
    "        try:\n",
    "            headers = {\n",
    "                'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.93 Safari/537.36'}\n",
    "            response = requests.get(resourceUrl + '?t=' + symbol, headers=headers)\n",
    "            soup = bs(markup=response.content, features=\"html.parser\")\n",
    "\n",
    "            for metric in fundamental_metrics:\n",
    "                metricValue = get_fundamental_metric(soup, metric)\n",
    "                df.loc[symbol, metric] = metricValue\n",
    "\n",
    "            name_sector_country = get_name_sector_country(soup)\n",
    "            for field in name_sector_country:\n",
    "                df.loc[symbol, field[0]] = field[1]\n",
    "        except Exception as e:\n",
    "            notFound.append(symbol)\n",
    "        print('Parsed ticker:', symbol)\n",
    "\n",
    "    return df, notFound"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get data from [Tinkoff API](https://tinkoffcreditsystems.github.io/invest-openapi/)\n",
    "\n",
    "Get monthly candles for the last two years\n",
    "\n",
    "Calculate growth for each month\n",
    "\n",
    "The expected growth calculate as mean growth for each month\n",
    "\n",
    "The risk is calculated using the standard deviation formula\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "token = os.environ['TINKOFF_INVEST_TOKEN']\n",
    "client = tinvest.SyncClient(token)\n",
    "\n",
    "\n",
    "def calculate_risk_and_expect_growth_in_month(ticker):\n",
    "    resp = make_request(client.get_market_search_by_ticker, ticker)\n",
    "    instruments = resp.payload.instruments\n",
    "\n",
    "    if len(instruments) == 0:\n",
    "        return None\n",
    "\n",
    "    figi = instruments[0].figi\n",
    "\n",
    "    candlesHistoryInMonth = make_request(client.get_market_candles,\n",
    "                                         figi,\n",
    "                                         '2019-01-01T00:00:00.00+00:00',\n",
    "                                         '2021-04-30T23:59:59.00+00:00',\n",
    "                                         CandleResolution.month)\n",
    "\n",
    "    prices = []\n",
    "    for candle in candlesHistoryInMonth.payload.candles:\n",
    "        prices.append((candle.h + candle.l) / 2)\n",
    "\n",
    "    growths = []\n",
    "    for i in range(0, len(prices) - 1):\n",
    "        growths.append(math.log(prices[i + 1] / prices[i]))\n",
    "\n",
    "    expect_growth = numpy.mean(growths)\n",
    "    risk = numpy.std(growths)\n",
    "\n",
    "    return expect_growth * 100, risk * 100  # To percent\n",
    "\n",
    "\n",
    "def make_request(request, *args):\n",
    "    try:\n",
    "        return request(*args)\n",
    "    except tinvest.TooManyRequestsError as e:\n",
    "        print('Too many request, wait 5 minute')\n",
    "        time.sleep(60 * 5 + 5)  # 5 min 5 sec\n",
    "        return request(tuple(args))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Save Received data from [FINVIZ](https://finviz.com/quote.ashx) and [Tinkoff API](https://tinkoffcreditsystems.github.io/invest-openapi/) in result csv\n",
    "\n",
    "After that, we can read data from CSV and fill ontology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_stocks(file_name='data.csv', separator=','):\n",
    "    stocks = []\n",
    "    table = pd.read_csv(file_name, sep=separator)\n",
    "    for row in table.iterrows():\n",
    "        stock = {}\n",
    "        for col in table.columns:\n",
    "            stock[col] = row[1][col]\n",
    "        stocks.append(stock)\n",
    "\n",
    "    return stocks\n",
    "\n",
    "def get_companies_sectors_countries(file_name='data.csv', separator=','):\n",
    "    table = pd.read_csv(file_name, sep=separator, parse_dates=[\n",
    "        'Name', 'Sector', 'Country'\n",
    "    ])\n",
    "\n",
    "    allCompanies = set()\n",
    "    allSectors = set()\n",
    "    allCountries = set()\n",
    "\n",
    "    for company in table['Name']:\n",
    "        allCompanies.add(company)\n",
    "\n",
    "    for sector in table['Sector']:\n",
    "        allSectors.add(sector)\n",
    "\n",
    "    for country in table['Country']:\n",
    "        allCountries.add(country)\n",
    "\n",
    "    return list(allCompanies), list(allSectors), list(allCountries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Declare Classes, Object properties and Data properties\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "URI = 'http://www.semanticweb.org/matvey/ontologies/2021/4/stock-market-ontology#'\n",
    "\n",
    "\n",
    "def to_URIRef(param):\n",
    "    result = URIRef(URI + param)\n",
    "    return result\n",
    "\n",
    "\n",
    "# Classes\n",
    "Asset = to_URIRef('Asset')\n",
    "Bond = to_URIRef('Bond')\n",
    "Company = to_URIRef('Company')\n",
    "Country = to_URIRef('Country')\n",
    "Currency = to_URIRef('Currency')\n",
    "Dividend = to_URIRef('Dividend')\n",
    "Fond = to_URIRef('Fond')\n",
    "Growth = to_URIRef('Growth')\n",
    "Index = to_URIRef('Index')\n",
    "Sector = to_URIRef('Sector')\n",
    "Stock = to_URIRef('Stock')\n",
    "\n",
    "# Object properties\n",
    "hasCompany = to_URIRef('hasCompany')\n",
    "hasCountry = to_URIRef('hasCountry')\n",
    "hasCurrency = to_URIRef('hasCurrency')\n",
    "includeInIndex = to_URIRef('includeInIndex')\n",
    "includeInSector = to_URIRef('includeInSector')\n",
    "\n",
    "# Data properties\n",
    "hasAverageDividendYield = to_URIRef('hasAverageDividendYield')\n",
    "hasPE = to_URIRef('hasPE')\n",
    "hasPS = to_URIRef('hasPS')\n",
    "hasPayoutRatio = to_URIRef('hasPayoutRatio')\n",
    "hasExpectGrowthInMonth = to_URIRef('hasExpectGrowInMonth')\n",
    "hasRisk = to_URIRef('hasRisk')\n",
    "hasBeta = to_URIRef('hasBeta')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill the ontology with data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def default_data_parser(value):\n",
    "    return value\n",
    "\n",
    "\n",
    "def percent_data_parser(value):\n",
    "    return value.replace('%', '')\n",
    "\n",
    "\n",
    "def default_name_parser(name):\n",
    "    return name.strip()\n",
    "\n",
    "\n",
    "def to_fixed(number, digits=2):\n",
    "    return f\"{number:.{digits}f}\"\n",
    "\n",
    "\n",
    "dataPropertyMap = {\n",
    "    'P/E': {\n",
    "        'relation': hasPE,\n",
    "        'data_parser': default_data_parser\n",
    "    },\n",
    "    'P/S': {\n",
    "        'relation': hasPS,\n",
    "        'data_parser': default_data_parser\n",
    "    },\n",
    "    'Dividend %': {\n",
    "        'relation': hasAverageDividendYield,\n",
    "        'data_parser': percent_data_parser\n",
    "    },\n",
    "    'Payout': {\n",
    "        'relation': hasPayoutRatio,\n",
    "        'data_parser': percent_data_parser\n",
    "    },\n",
    "    'Beta': {\n",
    "        'relation': hasBeta,\n",
    "        'data_parser': percent_data_parser\n",
    "    },\n",
    "    'Expect Growth in month': {\n",
    "        'relation': hasExpectGrowthInMonth,\n",
    "        'data_parser': to_fixed\n",
    "    },\n",
    "    'Risk': {\n",
    "        'relation': hasRisk,\n",
    "        'data_parser': to_fixed\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "def add_indexes(graph: Graph):\n",
    "    indexes = ['DJIA', 'S&P500']\n",
    "    return add_class_individuals_to_graph(graph, Index, indexes)\n",
    "\n",
    "\n",
    "def add_companies_sectors_countries(graph: Graph):\n",
    "    companies, sectors, countries = get_companies_sectors_countries()\n",
    "\n",
    "    companiesResult = add_class_individuals_to_graph(graph, Company, companies, lambda name: name.replace(',', '')\n",
    "                                                     .replace('.', '')\n",
    "                                                     .strip())\n",
    "    sectorsResult = add_class_individuals_to_graph(graph, Sector, sectors)\n",
    "    countriesResult = add_class_individuals_to_graph(graph, Country, countries)\n",
    "\n",
    "    return companiesResult, sectorsResult, countriesResult\n",
    "\n",
    "\n",
    "def add_stocks(graph: Graph, all_indexes_nodes, all_companies_nodes, all_sectors_nodes, all_countries_nodes):\n",
    "    stocks = get_stocks()\n",
    "\n",
    "    result = {}\n",
    "    for stock in stocks:\n",
    "        ticker = stock['Ticker']\n",
    "        stock_node = add_class_individual_to_graph(graph, Stock, ticker)\n",
    "        result[ticker] = stock_node\n",
    "\n",
    "        # Set object properties\n",
    "        company_node = all_companies_nodes[stock['Name']]\n",
    "        sector_node = all_sectors_nodes[stock['Sector']]\n",
    "        country_node = all_countries_nodes[stock['Country']]\n",
    "        indexes_nodes = get_indexes_nodes_for_stock(stock['Index'], all_indexes_nodes)\n",
    "\n",
    "        add_object_property(graph, stock_node, company_node, hasCompany)\n",
    "        add_object_property(graph, stock_node, sector_node, includeInSector)\n",
    "        add_object_property(graph, stock_node, country_node, hasCountry)\n",
    "        for index_node in indexes_nodes:\n",
    "            add_object_property(graph, stock_node, index_node, includeInIndex)\n",
    "\n",
    "        # Set data properties\n",
    "        for key in dataPropertyMap.keys():\n",
    "            dataPropertyInfo = dataPropertyMap[key]\n",
    "            value = stock[key]\n",
    "            if value == '-':\n",
    "                continue\n",
    "            parsed_value = dataPropertyInfo['data_parser'](value)\n",
    "            add_data_property(graph, stock_node, parsed_value, dataPropertyInfo['relation'])\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def add_class_individuals_to_graph(graph: Graph, Class: URIRef, names: list[string], parser=default_name_parser):\n",
    "    result = {}\n",
    "    for name in names:\n",
    "        result[name] = add_class_individual_to_graph(graph, Class, name, parser)\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def add_class_individual_to_graph(graph: Graph, Class: URIRef, name: string, parser=default_name_parser):\n",
    "    parsed_name = parser(name)\n",
    "    individual = to_URIRef(parsed_name.replace(' ', '_'))\n",
    "    triple = (individual, RDF.type, Class)\n",
    "    graph.add(triple)\n",
    "\n",
    "    return individual\n",
    "\n",
    "\n",
    "def add_object_property(graph, domain, client, relation):\n",
    "    triple = (domain, relation, client)\n",
    "    graph.add(triple)\n",
    "\n",
    "\n",
    "def add_data_property(graph, domain, value, relation):\n",
    "    triple = (domain, relation, Literal(value, datatype='xsd:float'))\n",
    "    graph.add(triple)\n",
    "\n",
    "\n",
    "def get_indexes_nodes_for_stock(stock_indexes: string, all_indexes_nodes):\n",
    "    if stock_indexes == '-':\n",
    "        return []\n",
    "\n",
    "    parsed_stock_indexes = stock_indexes.replace(' ', '')\n",
    "\n",
    "    result = []\n",
    "    for key in all_indexes_nodes.keys():\n",
    "        if key in parsed_stock_indexes:\n",
    "            result.append(all_indexes_nodes[key])\n",
    "\n",
    "    return result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}